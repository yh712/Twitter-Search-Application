{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please rememeber to put the path of file in the \"with open section\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "# you have to install mongodb using command line before using the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-12a5b5de7beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'twitter_collection'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tweets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets'"
     ]
    }
   ],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['twitter_db']\n",
    "collection = db['twitter_collection']\n",
    "import json\n",
    "with open(\"tweets\", \"r\") as f1:\n",
    "    for line in f1:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            # if you want to see a specific field, you can print it. \n",
    "            # if your file is big, there may be too many of these printed\n",
    "            # print(data['text'])\n",
    "            # insert data into MongoDB\n",
    "            collection.insert_one(data)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Define client, db, collection\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['twitter_db']\n",
    "collection = db['twitter_collection']\n",
    "\n",
    "# find one record in twitter_collection\n",
    "x = collection.find_one()\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15633\n"
     ]
    }
   ],
   "source": [
    "# check how many tweets have been retweeted \n",
    "cursor = db.twitter_collection.find({\"retweeted_status\": {\"$exists\": True}})\n",
    "num_of_tweets_retweeted = 0 \n",
    "for doc in cursor:\n",
    "    num_of_tweets_retweeted += 1\n",
    "print(num_of_tweets_retweeted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create several indexes in this table for fast access\n",
    "\n",
    "If not creating indexes, it may require traversal the whole table to find the information. With index, (MongoDB stores indexes using BTree data structure), the search time complexity can be reduced a lot. (Generally, can from O(N) to O(logN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retweeted_status.reply_count_-1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a single filed index for users' followers_count to speed up the access for each single tweet based \n",
    "# on the number of their followers\n",
    "collection.create_index([(\"user.followers_count\", pymongo.DESCENDING)])\n",
    "\n",
    "# create an index on \"created_at\"\n",
    "collection.create_index([(\"created_at\", pymongo.DESCENDING)])\n",
    "\n",
    "# create an index on \"retweeted_status.retweet_count\"\n",
    "collection.create_index([(\"retweeted_status.retweet_count\", pymongo.DESCENDING)])\n",
    "\n",
    "# create an index on \"retweeted_status.reply_count\"\n",
    "collection.create_index([(\"retweeted_status.reply_count\", pymongo.DESCENDING)])\n",
    "\n",
    "# look at executionTimeMillis for search time, the smaller executionTimeMillis is better \n",
    "# cursor.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create another collection named \"first_100_tweets_table\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another collection named first_100_tweets_table\n",
    "collection_2 = db['first_100_tweets_table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following chunk of code can only be run once, and it insert the first 100 tweets into this collection one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_100_tweets = db.twitter_collection.find().sort(\"created_at\", -1).limit(100)\n",
    "#for doc in first_100_tweets:\n",
    "#    collection_2.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find one doc in the new collection \"first_100_tweets_table\"\n",
    "y = collection_2.find_one()\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a deep copy of the first_100_tweets_table in this program, and it will be used as a in program database, which can be accessed faster than the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep copy of the first_100_tweets_table in this program, and it can be accessed faster than the database\n",
    "cache_in_program = []\n",
    "cursor = db.first_100_tweets_table.find()\n",
    "for doc in cursor:\n",
    "    cache_in_program.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some queries using MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19171\n"
     ]
    }
   ],
   "source": [
    "# find the number of tweets in this database \n",
    "cursor = db.twitter_collection.find()\n",
    "num_of_tweets = 0 \n",
    "for doc in cursor:\n",
    "    num_of_tweets += 1\n",
    "print(num_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…\n"
     ]
    }
   ],
   "source": [
    "# find the content of the newest tweet\n",
    "newest_tweet = db.first_100_tweets_table.find().limit(1) \n",
    "for doc in newest_tweet:\n",
    "    content_of_newest_tweet = doc['text']\n",
    "    print(content_of_newest_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 15 00:56:34 +0000 2020\n"
     ]
    }
   ],
   "source": [
    "# find the time of the latest tweet created in this database\n",
    "newest_tweet = db.first_100_tweets_table.find().limit(1) \n",
    "for doc in newest_tweet:\n",
    "    created_time_of_newest_tweet = doc['created_at']\n",
    "print(created_time_of_newest_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id: 1115874631\n",
      "user name: CGTN\n"
     ]
    }
   ],
   "source": [
    "# find the user id of the user who has the largest number of followers in this database\n",
    "user_with_largest_num_of_followers = db.twitter_collection.find({}, {\"user.id\", \"user.name\", \"user.followers_count\"}).sort(\"user.followers_count\", -1).limit(1)\n",
    "for doc in user_with_largest_num_of_followers:\n",
    "    user_id_with_largest_num_of_followers = doc['user']['id']\n",
    "    user_name_with_largest_num_of_followers = doc['user']['name']\n",
    "print(\"user id: \" + str(user_id_with_largest_num_of_followers) + \"\\nuser name: \" + user_name_with_largest_num_of_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "# find how many users in this database have more than 100k followers\n",
    "cursor = db.twitter_collection.find({\"user.followers_count\": {\"$gt\": 100000}}, {\"user.id\", \"user.followers_count\"})\n",
    "num_of_users_with_gt100k_followers = 0 \n",
    "for doc in cursor:\n",
    "    num_of_users_with_gt100k_followers += 1\n",
    "print(num_of_users_with_gt100k_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the other countries are making the US look like it’s being ran by a moron\n",
      "All the other countries are making the US look like it’s being ran by a moron\n",
      "All the other countries are making the US look like it’s being ran by a moron\n",
      "All the other countries are making the US look like it’s being ran by a moron\n",
      "All the other countries are making the US look like it’s being ran by a moron\n"
     ]
    }
   ],
   "source": [
    "# find the tweets with most retweets\n",
    "most_retweets = db.twitter_collection.find({}, {\"retweeted_status.text\", \"retweeted_status.retweet_count\"}).sort(\"retweeted_status.retweet_count\", -1).limit(5)\n",
    "for doc in most_retweets:\n",
    "    tweets_with_most_retweets = doc['retweeted_status']['text']\n",
    "    print(tweets_with_most_retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tweets made by users who are verified\n",
    "verified = db.twitter_collection.find({\"user.verified\": {\"$exists\": True}})\n",
    "for doc in verified:\n",
    "    verified_tweets = doc['text']\n",
    "    verified_tweets_name = doc['user']['name']\n",
    "    #print(\"Name:\", verified_tweets_name, \"\\nTweet:\", verified_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of a tweet in this database is 123.95425382087528 characters.\n"
     ]
    }
   ],
   "source": [
    "# get the average character length of all the tweets\n",
    "all_tweets = db.twitter_collection.find()\n",
    "sum = 0\n",
    "for doc in all_tweets:\n",
    "    tweet = doc['text']\n",
    "    sum += len(tweet)\n",
    "    \n",
    "average_length = sum/num_of_tweets\n",
    "print(\"The average length of a tweet in this database is\",average_length, \"characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "Everyone, young and old, needs to act now to slow the spread of COVID-19.  The best thing Americans can to do fight… https://t.co/t9BooCw8QS\n",
      "\n",
      "140\n",
      "Everyone, young and old, needs to act now to slow the spread of COVID-19.  The best thing Americans can to do fight… https://t.co/t9BooCw8QS\n",
      "\n",
      "140\n",
      "Everyone, young and old, needs to act now to slow the spread of COVID-19.  The best thing Americans can to do fight… https://t.co/t9BooCw8QS\n",
      "\n",
      "140\n",
      "Preliminary investigations conducted by the Chinese authorities have found no clear evidence of human-to-human tran… https://t.co/1GHUbI2YXm\n",
      "\n",
      "140\n",
      "Preliminary investigations conducted by the Chinese authorities have found no clear evidence of human-to-human tran… https://t.co/1GHUbI2YXm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find tweets with the most replies (most controversial)\n",
    "most_replies = db.twitter_collection.find({}, {\"retweeted_status.text\", \"retweeted_status.reply_count\"}).sort(\"retweeted_status.reply_count\", -1).limit(5)\n",
    "for doc in most_replies:\n",
    "    length_of_tweets_with_most_replies = len(doc['retweeted_status']['text'])\n",
    "    print(length_of_tweets_with_most_replies)\n",
    "    tweets_with_most_replies = doc['retweeted_status']['text']\n",
    "    print(tweets_with_most_replies)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting tweets that are blow a certain character length\n",
    "# length = 40\n",
    "# all_tweets = db.twitter_collection.find({}, {\"retweeted_status\", \"retweeted_status.text\"})\n",
    "# for doc in all_tweets:\n",
    "#     # if tweet is less than desired length, add it\n",
    "#     if (len(doc['retweeted_status']['text']) < length):\n",
    "#         short_tweets = doc['retweeted_status']['text']\n",
    "#         #print(short_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 1115874631\n",
      "Number of followers: 14024195\n",
      "Tweet: Numbers from the Chinese mainland on Tuesday: one new #COVID19 death in #Hubei; 46 new cases (36 originating abroad… https://t.co/Fw6RKZoDQf\n",
      "User ID: 37034483\n",
      "Number of followers: 12616711\n",
      "Tweet: Here's how drones helping India in fight against #coronavirus https://t.co/ATdiBectqs https://t.co/Cx6dH0Hc2O\n"
     ]
    }
   ],
   "source": [
    "# find tweets from people with the most followers\n",
    "most_followers = db.twitter_collection.find({}, {\"user.id\", \"user.followers_count\", \"text\"}).sort(\"user.followers_count\", -1).limit(2)\n",
    "for doc in most_followers:\n",
    "    user_id_with_most_followers = doc['user']['id']\n",
    "    follower_count = doc['user']['followers_count']\n",
    "    tweets_by_most_followers = doc['text']\n",
    "    tweets_from_people_with_most_followers = \"User ID: \" + str(user_id_with_most_followers) + \"\\nNumber of followers: \" + str(follower_count) + \"\\nTweet: \" + tweets_by_most_followers\n",
    "    print(tweets_from_people_with_most_followers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare answers to some common questions in the program which will be put into cache later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_questions = {\n",
    "    \"Number of tweets in database?\": num_of_tweets,\n",
    "    \"What is the content of the newest tweet?\": content_of_newest_tweet,\n",
    "    \"What time is the latest tweet created in this database?\": created_time_of_newest_tweet,\n",
    "    \"What is the user id of the user who has the largest number of followers in this database?\": \"user id: \" + str(user_id_with_largest_num_of_followers) + \"\\nuser name: \" + user_name_with_largest_num_of_followers,\n",
    "    \"What is the content of the tweet with most retweets? \": tweets_with_most_retweets,\n",
    "    \"How many users in this database have more than 100k followers?\": num_of_users_with_gt100k_followers,\n",
    "    \"What is the average length of a tweet in this database?\": average_length,\n",
    "    \"What is the tweet with most replies, and how many replies it gets?\": tweets_with_most_replies + \"\\n\" + str(length_of_tweets_with_most_replies) + \" replies\",\n",
    "    \"What is the tweet from people with most followers? \": tweets_from_people_with_most_followers\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in database? 19171\n",
      "What is the content of the newest tweet? RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…\n",
      "What time is the latest tweet created in this database? Wed Apr 15 00:56:34 +0000 2020\n",
      "What is the user id of the user who has the largest number of followers in this database? user id: 1115874631\n",
      "user name: CGTN\n",
      "What is the content of the tweet with most retweets?  All the other countries are making the US look like it’s being ran by a moron\n",
      "How many users in this database have more than 100k followers? 167\n",
      "What is the average length of a tweet in this database? 123.95425382087528\n",
      "What is the tweet with most replies, and how many replies it gets? Preliminary investigations conducted by the Chinese authorities have found no clear evidence of human-to-human tran… https://t.co/1GHUbI2YXm\n",
      "140 replies\n",
      "What is the tweet from people with most followers?  User ID: 37034483\n",
      "Number of followers: 12616711\n",
      "Tweet: Here's how drones helping India in fight against #coronavirus https://t.co/ATdiBectqs https://t.co/Cx6dH0Hc2O\n"
     ]
    }
   ],
   "source": [
    "for i, val in common_questions.items():\n",
    "    print(i, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRU Cache for questions asked\n",
    "### LRU Cache is a cache replacement algorithm that removes the least recently used data in order to make room for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRU Cache requires the linkedlist structure, but Python does not have it, so we have to create a LinkedNode class\n",
    "# key is the question, value is the answer to that question, next is the next question of this question in the cache\n",
    "class LinkedNode:\n",
    "    \n",
    "    def __init__(self, key=None, value=None, next=None):\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.next = next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRU Cache is a cache replacement algorithm that removes the least recently used data in order to make room for \n",
    "# new data.\n",
    "class LRUCache:\n",
    "    \n",
    "        # This is the initial function to define \n",
    "        # Dictionary(key_to_prev): key is the question, value is the linkednode of the previous question\n",
    "        # LinkedNode(dummy): the linkednode without value to point out the memory address of the linkedlist\n",
    "        # tail: the tail of the linkedlist, and its initial value is dummy\n",
    "        # Integer(capacity): define of the size of the cache, which is the same as the length of the linkedlist\n",
    "        def __init__(self, capacity):\n",
    "            self.key_to_prev = {}\n",
    "            self.dummy = LinkedNode()\n",
    "            self.tail = self.dummy\n",
    "            self.capacity = capacity\n",
    "        \n",
    "        # The function push_back is to put the question node at the tail of the linkedlist\n",
    "        def push_back(self, node):\n",
    "            self.key_to_prev[node.key] = self.tail\n",
    "            self.tail.next = node\n",
    "            self.tail = node\n",
    "        \n",
    "        # The function pop_front is to delete the head node from the linkedlist and the next node becomes the new head\n",
    "        def pop_front(self):\n",
    "            head = self.dummy.next\n",
    "            del self.key_to_prev[head.key]\n",
    "            self.dummy.next = head.next\n",
    "            self.key_to_prev[head.next.key] = self.dummy\n",
    "            \n",
    "        # The function kick is to move the prev node's next to the tail of the linkedlist\n",
    "        def kick(self, prev): \n",
    "            node = prev.next\n",
    "            if node == self.tail:\n",
    "                return\n",
    "        \n",
    "            # remove the current node from linked list\n",
    "            prev.next = node.next\n",
    "            # update the previous node in hash map\n",
    "            self.key_to_prev[node.next.key] = prev\n",
    "            node.next = None\n",
    "\n",
    "            self.push_back(node)\n",
    "        \n",
    "        # The function get is to get the value(answer) of the key(question)\n",
    "        # If the question is not in the linkedlist, it will return -1, and we need go to the database to find answers\n",
    "        # Else: it will return the value(answer) of the key(question)\n",
    "        def get(self, key):\n",
    "            if key not in self.key_to_prev:\n",
    "                return -1\n",
    "        \n",
    "            prev = self.key_to_prev[key]\n",
    "            current = prev.next\n",
    "        \n",
    "            self.kick(prev)\n",
    "            return current.value\n",
    "        \n",
    "        # The function put is to put a question into the linkedlist\n",
    "        def set(self, key, value):\n",
    "            # If the question is in the cache, it will move the question from the original node position to the \n",
    "            # tail of the original linkedlist\n",
    "            if key in self.key_to_prev:\n",
    "                self.kick(self.key_to_prev[key])\n",
    "                self.key_to_prev[key].next.value = value\n",
    "                return\n",
    "            \n",
    "            # If the question is not in cache, it will be inseretd to the linkedlist\n",
    "            self.push_back(LinkedNode(key, value))\n",
    "            # In addition, if the cache reached its capacity, it will invaliaded the lease recently used question \n",
    "            # before inserting the new question \n",
    "            if len(self.key_to_prev) > self.capacity:\n",
    "                self.pop_front()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LRU Cache algorithm to cache of questions asked in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # set the size of the cache be 20 questions\n",
    "    LRU_Cache = LRUCache(20)\n",
    "\n",
    "    # put several common questions into cache firstly\n",
    "    for question in common_questions:\n",
    "        LRU_Cache.set(question, common_questions[question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19171"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU_Cache.get(\"Number of tweets in database?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU_Cache.get(\"What is the content of the newest tweet?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRU_Cache.get(\"What is LRU Cache?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial attempt: Design a basic serach application UI with the questions and answers based on common_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some packages for user interface design \n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider\n",
    "\n",
    "# define a function f to return the answer to the input question \n",
    "def f(Question):\n",
    "    print(common_questions[Question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71431a61f6b4be5bbea4c487f6e8fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Question', options=('Number of tweets in database?', 'What is the …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# interface for user to do question search \n",
    "def search_application():\n",
    "    interact(f, Question = [x for x in common_questions])\n",
    "search_application()\n",
    "# import timeit\n",
    "# print(timeit.timeit(search_application, number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = widgets.Dropdown(\n",
    "#     options = common_questions,\n",
    "#     description = 'Please pick a question:', \n",
    "#     style = style, \n",
    "#     layout = {'width': 'max-content'})\n",
    "# display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check running time of the common questions for search application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…\n",
      "5.926200000061499e-05\n"
     ]
    }
   ],
   "source": [
    "def common_question_in_cache():\n",
    "    print(common_questions[\"What is the content of the newest tweet?\"])\n",
    "\n",
    "import timeit\n",
    "print(timeit.timeit(common_question_in_cache, number=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19171\n",
      "4.860399999984111e-05\n"
     ]
    }
   ],
   "source": [
    "def common_question_in_cache():\n",
    "    print(common_questions[\"Number of tweets in database?\"])\n",
    "\n",
    "import timeit\n",
    "print(timeit.timeit(common_question_in_cache, number=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement on Search Application based on LRU Cache and More Questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NewTweet is to find the created_time, user_id, user_name and content of newest tweets\n",
    "class NewTweet:\n",
    "    \n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "    \n",
    "    def find_tweet_content(self):\n",
    "        newest_tweet = db.first_100_tweets_table.find().limit(self.number)\n",
    "        index = 1\n",
    "        result = []\n",
    "        for doc in newest_tweet:\n",
    "            temp = []\n",
    "            content = doc['text']\n",
    "            created_time = doc['created_at']\n",
    "            user_id = doc['user']['id']\n",
    "            user_name = doc['user']['name']\n",
    "            temp.append(\"No. \" + str(index))\n",
    "            temp.append(created_time + \" User ID: \" + str(user_id) + \" User Name: \" + user_name)\n",
    "            temp.append(content_of_newest_tweet)\n",
    "            result.append(temp)\n",
    "            index += 1\n",
    "        return result\n",
    "\n",
    "# FamousUsers is to find the user_id, user_name and number_of_followers of users with most followers\n",
    "class FamousUsers:\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "    \n",
    "    def find_famous_users(self):\n",
    "        # find the user id of the user who has the largest number of followers in this database\n",
    "        user_with_largest_num_of_followers = db.twitter_collection.find({}, {\"user.id\", \"user.name\", \"user.followers_count\"}).sort(\"user.followers_count\", -1).limit(self.number)\n",
    "        index = 1\n",
    "        result = []\n",
    "        for doc in user_with_largest_num_of_followers:\n",
    "            temp = []\n",
    "            user_id = doc['user']['id']\n",
    "            user_name = doc['user']['name']\n",
    "            number_of_followers = doc['user']['followers_count']\n",
    "            temp.append(\"No. \" + str(index))\n",
    "            temp.append(\"User ID: \" + str(user_id) + \"\\nUser Name: \" + user_name + \"\\nFollowers: \" + str(number_of_followers))\n",
    "            result.append(temp)\n",
    "            index += 1\n",
    "        return result\n",
    "\n",
    "            \n",
    "from collections import Counter\n",
    "# PopularWords is to find words which have been used most in this dataset\n",
    "class PopularWords:\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "    \n",
    "    def find_popular_words(self):\n",
    "        sentences = db.twitter_collection.find({}, {\"text\"})\n",
    "        word_dictionary = {}\n",
    "        for doc in sentences:\n",
    "            sentence = doc['text']\n",
    "            for word in sentence.split():\n",
    "                if word in word_dictionary:\n",
    "                    word_dictionary[word] += 1\n",
    "                else:\n",
    "                    word_dictionary[word] = 1\n",
    "        k = Counter(word_dictionary)\n",
    "        high = k.most_common(self.number)\n",
    "        index = 1\n",
    "        result = []\n",
    "        for word in high:\n",
    "            temp = []\n",
    "            temp.append(\"No. \" + str(index))\n",
    "            temp.append(word[0] + \": \" + str(word[1]))\n",
    "            result.append(temp)\n",
    "            index += 1\n",
    "        return result\n",
    "\n",
    "# TweetsFromFamousUsers is to find tweets from people with the most followers\n",
    "class TweetsFromFamousUsers:\n",
    "    def __init__(self, number):\n",
    "        self.number = number\n",
    "        \n",
    "    def find_tweets_from_famous_users(self):\n",
    "        most_followers = db.twitter_collection.find({}, {\"user.id\", \"user.followers_count\", \"text\"}).sort(\"user.followers_count\", -1).limit(self.number)\n",
    "        index = 1\n",
    "        result = []\n",
    "        for doc in most_followers:\n",
    "            user_id = doc['user']['id']\n",
    "            follower_count = doc['user']['followers_count']\n",
    "            tweet = doc['text']\n",
    "            tweets_from_famous_users = \"User ID: \" + str(user_id) + \"\\nNumber of Followers: \" + str(follower_count) + \"\\nTweet: \" + tweet\n",
    "            temp = []\n",
    "            temp.append(\"No. \" + str(index))\n",
    "            temp.append(tweets_from_famous_users)\n",
    "            result.append(temp)\n",
    "            index += 1\n",
    "        return result\n",
    "\n",
    "# ValidQuestion is to find the question to its related query \n",
    "class ValidQuestion:\n",
    "    \n",
    "    def __init__(self, question, number):\n",
    "        self.question = question\n",
    "        self.number = number\n",
    "    \n",
    "    def get_question(self):\n",
    "        if self.question == \"Find Newest Tweets\":\n",
    "            new_tweet = NewTweet(self.number)\n",
    "            return new_tweet.find_tweet_content()\n",
    "        \n",
    "        elif self.question == \"Find Famous Users\":\n",
    "            famous_users = FamousUsers(self.number)\n",
    "            return famous_users.find_famous_users()\n",
    "\n",
    "        elif self.question == \"Find popular words\":\n",
    "            popular_words = PopularWords(self.number)\n",
    "            return popular_words.find_popular_words()\n",
    "        \n",
    "        elif self.question == \"Find tweets from famous users\":\n",
    "            tweets_from_famous_users = TweetsFromFamousUsers(self.number)\n",
    "            return tweets_from_famous_users.find_tweets_from_famous_users()\n",
    "        \n",
    "        else:\n",
    "            print(\"We don't have this question in search application!\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "dropdown_count = widgets.Dropdown(options = [x for x in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropdown_count(change):\n",
    "    valid_question \n",
    "    display(df_london[df_london.year == change.new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['No. 1',\n",
       "  'Wed Apr 15 00:56:34 +0000 2020 User ID: 22091137 User Name: Basu Ghosh Das',\n",
       "  'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…'],\n",
       " ['No. 2',\n",
       "  'Wed Apr 15 00:56:34 +0000 2020 User ID: 531629036 User Name: Creeds Cannon',\n",
       "  'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…'],\n",
       " ['No. 3',\n",
       "  'Wed Apr 15 00:56:34 +0000 2020 User ID: 1042203452212948992 User Name: christy��️\\u200d��',\n",
       "  'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…'],\n",
       " ['No. 4',\n",
       "  'Wed Apr 15 00:56:34 +0000 2020 User ID: 3551287573 User Name: david lee',\n",
       "  'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…'],\n",
       " ['No. 5',\n",
       "  'Wed Apr 15 00:56:33 +0000 2020 User ID: 3294199050 User Name: Josh M.',\n",
       "  'RT @TarekFatah: Pakistanis in Karachi defying orders not to congregate in mosques by creating makeshift mosques on rooftops. Working hard t…']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_question = ValidQuestion(\"Find Newest Tweets\", 5)\n",
    "valid_question.get_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "class SearchApplicationOne:\n",
    "    def __init__(self, capacity):\n",
    "        self.LRU_Cache = LRUCache(capacity)\n",
    "    \n",
    "    def user_interface(self):\n",
    "        @interact(options = widgets.Dropdown(options=['Find Newest Tweets', 'Find Famous Users', 'Find popular words', \n",
    "                                              'Find tweets from famous users'],\n",
    "            value='Find Newest Tweets',\n",
    "            description='Question:',\n",
    "            disabled=False), \n",
    "            Top = widgets.IntSlider(min = 1, max = 100, step = 1, description = \"Top: \", value = 1))\n",
    "\n",
    "        def f(options, Top):\n",
    "            if self.LRU_Cache.get((options, Top)) != -1:\n",
    "                answers = self.LRU_Cache.get((options, Top))\n",
    "                for answer in answers:\n",
    "                    for val in answer:\n",
    "                        print(val)\n",
    "                    print()\n",
    "            else:\n",
    "                valid_question = ValidQuestion(options, Top)\n",
    "                answers = valid_question.get_question()\n",
    "                self.LRU_Cache.set((options, Top), answers)\n",
    "                for answer in answers:\n",
    "                    for val in answer:\n",
    "                        print(val)\n",
    "                    print()\n",
    "            print(self.LRU_Cache.key_to_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6264f244e76469b966a845a2cac3864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Question:', options=('Find Newest Tweets', 'Find Famous Users', 'F…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "serach_appliaction = SearchApplicationOne(5)\n",
    "serach_appliaction.user_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
